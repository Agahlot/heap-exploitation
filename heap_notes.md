Analysis as of 27 March, 2017

Version: http://repo.or.cz/glibc.git/blob/17f487b7afa7cd6c316040f3e6c86dc96b2eec30:/malloc/malloc.c


# Notes:

1. Instead of `size_t`, `INTERNAL_SIZE_T` is used internally(which by default is [equal](http://repo.or.cz/glibc.git/blob/17f487b7afa7cd6c316040f3e6c86dc96b2eec30:/malloc/malloc.c#l175) to `size_t`).

2. Alignment is defined as `2 * (sizeof(size_t))`.

3. `MORECORE` is defined as the routine to call to obtain more memory. By default it is [defined](http://repo.or.cz/glibc.git/blob/17f487b7afa7cd6c316040f3e6c86dc96b2eec30:/malloc/malloc.c#355) as `sbrk`.

# Type definitions:

## malloc_chunk

```c
struct malloc_chunk {
  INTERNAL_SIZE_T      mchunk_prev_size;  /* Size of previous chunk (if free).  */
  INTERNAL_SIZE_T      mchunk_size;       /* Size in bytes, including overhead. */
  struct malloc_chunk* fd;         /* double links -- used only if free. */
  struct malloc_chunk* bk;
  /* Only used for large blocks: pointer to next larger size.  */
  struct malloc_chunk* fd_nextsize; /* double links -- used only if free. */
  struct malloc_chunk* bk_nextsize;
};

typedef struct malloc_chunk* mchunkptr;
```

This structure represents a particular chunk of memory. The various fields have different meaning for allocated and unallocated chunks.

Allocated chunk:

```
    chunk-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
     	    |             Size of previous chunk, if unallocated (P clear)  |
	        +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
     	    |             Size of chunk, in bytes                     |A|M|P|
      mem-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
	        |             User data starts here...                          .
     	    .                                                               .
     	    .             (malloc_usable_size() bytes)                      .
     	    .                                                               |
nextchunk-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
     	    |             (size of chunk, but used for application data)    |
	        +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
     	    |             Size of next chunk, in bytes                |A|0|1|
	        +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
```

Notice how the data of an allocated chunk uses the first attribute(`mchunk_prev_size`) of the next chunk. `mem` is the pointer which is returned to the user.

Free chunk:

```

    chunk-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
     	    |             Size of previous chunk, if unallocated (P clear)  |
	        +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    `head:' |             Size of chunk, in bytes                     |A|0|P|
      mem-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
     	    |             Forward pointer to next chunk in list             |
	        +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
     	    |             Back pointer to previous chunk in list            |
	        +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
     	    |             Unused space (may be 0 bytes long)                .
	        .                                                               .
     	    .                                                               |
nextchunk-> +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    `foot:' |             Size of chunk, in bytes                           |
     	    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
     	    |             Size of next chunk, in bytes                |A|0|0|
     	    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
```

Free chunks maintain themselves in a circular doubly linked list.

P (PREV_INUSE): 0 when previous chunk(not the previous chunk in the linked list, but the one directly before it in memory) is free(and hence the size of previous chunk is stored in the first field). The very first chunk allocated has this bit set. If it is 1, then we cannot determine the size of the previous chunk.

M (IS_MMAPPED): The chunk is obtained through `mmap`. The other two bits are ignored. `mmapped` chunks are neither in an arena, not adjacent to a free chunk.

A (NON_MAIN_ARENA): 0 for chunks in the main arena. Each thread spawned receives its own arena and for those chunks this bit is set.

Note: Chunks in fastbins are treated as _allocated_ chunks.

## malloc_state

```c
struct malloc_state
{
  /* Serialize access.  */
  __libc_lock_define (, mutex);
  /* Flags (formerly in max_fast).  */
  int flags;
  /* Fastbins */
  mfastbinptr fastbinsY[NFASTBINS];
  /* Base of the topmost chunk -- not otherwise kept in a bin */
  mchunkptr top;
  /* The remainder from the most recent split of a small request */
  mchunkptr last_remainder;
  /* Normal bins packed as described above */
  mchunkptr bins[NBINS * 2 - 2];
  /* Bitmap of bins */
  unsigned int binmap[BINMAPSIZE];
  /* Linked list */
  struct malloc_state *next;
  /* Linked list for free arenas.  Access to this field is serialized
     by free_list_lock in arena.c.  */
  struct malloc_state *next_free;
  /* Number of threads attached to this arena.  0 if the arena is on
     the free list.  Access to this field is serialized by
     free_list_lock in arena.c.  */
  INTERNAL_SIZE_T attached_threads;
  /* Memory allocated from the system in this arena.  */
  INTERNAL_SIZE_T system_mem;
  INTERNAL_SIZE_T max_system_mem;
};
typedef struct malloc_state *mstate;
```

This structure represents the header details of an Arena. The main thread's arena is a global variable and not part of the heap segment. Arena headers(`malloc_state` structures) for other threads are themselves stored on the heap segment. Non main arenas can have multiple heaps('heap' here refers to the internal structure used instead of the heap segment) associated with them.

# bins

A bin is a list(doubly or singly linked list) of free(non allocated) chunks. Bins are differentiated based on the size of chunks they contain:

1. Fast bin
2. Unsorted bin
3. Small bin
4. Large bin

Fast bins are maintained using:

```c
typedef struct malloc_chunk *mfastbinptr;

mfastbinptr fastbinsY[]; // Array of pointers to chunks
```

Unsorted, small and large bis are maintained using a single array:

```c
typedef struct malloc_chunk* mchunkptr;

mchunkptr bins[]; // Array of poiters to chunks
```

Initially, during initialization process, small and large bins are empty.

Each bin is represented by two values in the bins array. The first one is a pointer for the 'HEAD' and the second one is a pointer for the 'TAIL' of the bin list. In case of fast bins, the second value is NULL.

## Fast bins

There are a total of 10 fast bins. Each of these bin maintains a single linked list. Addition and deletion happens from front of this list(LIFO manner).

Each bin has chunks of the same size. The 10 bins have each chunks of sizes: 16, 24, 32, 40, 48, 56, 64, 72,80 and 88. Sizes mentioned here include metadata as well. To store chunks, 4 less bytes will be available(on a platform where pointers use 4 bytes. Only the `size` field will hold meta data for allocated chunks. `prev_size` of next contiguous chunk will hold user data.)

No two contiguous free fast chunks are coalesced together.

## Unsorted bin

There is only 1 unsorted bin. Small and large chunks, when freed, end up in this bin. The primary purpose of this bin is to act as a cache layer(kind of) to speed up allocation and deallocation requests.

## Small bins

There are 62 small bins. Small bins are faster than large bins but slower than fast bins. Each bin maintains a doubly linked list. Insertions happen at the 'HEAD' while removals happen at the 'TAIL'(in a FIFO manner).

Like fast bins, each bin has chunks of the same size. The 62 bins have sizes: 16, 24, ... , 504 bytes.

While freeing, small chunks may be coalesced together before ending up in unsorted bins.

## Large bins

There are 63 large bins. Each bin maintains a doubly liked list. A particular large bin has chunks of different sizes, sorted in decreasing order(i.e. largest chunk at the 'HEAD' and smallest chunk at the 'TAIL'). Insertions and removals happen at any position within the list.

The first 32 bins contain chunks which are 64 bytes apart:

1st bin: 512 - 568 bytes
2nd bin: 576 - 632 bytes
.
.

To summarize:

```
64 bins of size       8  [ Small bins]
32 bins of size      64  [ Large bins]
16 bins of size     512  [ Large bins]
8 bins of size     4096  [ ..        ]
4 bins of size    32768
2 bins of size   262144
1 bin  of size what's left
```

Like small chunks, while freeing, large chunks may be coalesced together before ending up in unsorted bins.

There are two special types of chunks which are not part of any bin.

## Top chunk

It is the chunk which borders the top of an arena. While servicing 'malloc' requests, it is used as the last resort. If still more size is required, it can grow using the `sbrk` system call. The `PREV_INUSE` flag is always set for the top chunk.

## Last remainder chunk

It is the chunk obtained from the last split. Sometimes, when exact size chunks are not available, bigger chunks are split into two. One part is returned to the user whereas the other becomes the last remainder chunk.

# Internal procedures

Note that some procedures are in fact defined using the `#define` directive. So, changes to parameters are in fact retained after the call. Also, it is assumed that MALLOC_DEBUG is not set.

## arena_get (ar_ptr, bytes)

Acquires an arena and locks the corresponding mutex. `ar_ptr` is set to point to the corresponding arena. `size` is just a hint as to how much memory will be required immediately.

## sysmalloc [TODO]

```c
/*
   sysmalloc handles malloc cases requiring more memory from the system.
   On entry, it is assumed that av->top does not have enough
   space to service request for nb bytes, thus requiring that av->top
   be extended or replaced.
 *
```

## void alloc_perturb (char *p, size_t n)

If `perturb_byte`(tunable parameter for malloc using `M_PERTURB`) is non zero(by default it is 0), sets the `n` bytes pointed to by `p` to be equal to `perturb_byte` ^ 0xff.

## void free_perturb (char *p, size_t n)

If `perturb_byte`(tunable parameter for malloc using `M_PERTURB`) is non zero(by default it is 0), sets the `n` bytes pointed to by `p` to be equal to `perturb_byte`.

## void malloc_init_state (mstate av) [TODO]

```c
/*
   Initialize a malloc_state struct.

   This is called only from within malloc_consolidate, which needs
   be called in the same contexts anyway.  It is never called directly
   outside of malloc_consolidate because some optimizing compilers try
   to inline it at all call points, which turns out not to be an
   optimization at all. (Inlining it in malloc_consolidate is fine though.)
 */
```

## void malloc_consolidate(mstate av)

This is a specialized version of free().

1. Chech if `global_max_fast` is 0 or not. If it is 0, call `malloc_init_state` with `av` as parameter and return.
2. If `global_max_fast` is non zero, clear the `FASTCHUNKS_BIT` for `av`.
3. Iterate on fastbin array from first to last indices:
   1. Get a lock on the current fastbin.
   2. 

## void * _int_malloc (mstate av, size_t bytes)

1. Updates `bytes` to take care of alignments, etc.
2. Checks if `av` is NULL or not.
3. In case of absence of usable arena(when `av` is NULL), calls `sysmalloc` to obtain chunk using mmap. If successful, calls `alloc_perturb`. Returns the pointer.
4.
  - If size falls in fastbin range:
    1. Get index into fastbin array to access an appropriate bin according to the request size.
    2. Removes the first chunk in that bin and make `victim` point to it.
    3. If `victim` is NULL, move on to the next case(smallbin).
    4. If `victim` is not NULL, check the size of the chunk to ensure that it belongs to that particular bin. An error("malloc(): memory corruption (fast)") is thrown otherwise.
    5. Calls `alloc_perturb` and then returns the pointer.

  - If size falls in smallbin range:
    1. Get index into smallbin array to access an appropriate bin according to the request size.
    2. If there are no chunks in this bin, move on to the next case. This is checked by comparing the pointers `bin` and `bin->bk`.
    3. `victim` is made equal to `bin->bk`(the last chunk in the bin). If it is NULL(happens during `initialization`), call `malloc_consolidate` and skip this complete step of checking into different bins.
    4. Otherwise, when `victim` is non NULL, check if `victim->bk->fd` and `victim` are equal or not. If they are not equal, an error("malloc(): smallbin double linked list corrupted") is thrown.
    5. Sets the PREV_INSUSE bit for the next chunk(in memory, not in the doubly linked list) for `victim`.
    6. Remove this chunk from the binlist.
    7. Set the appropriate arena bit for this chunk depending on `av`.
    8. Calls `alloc_perturb` and then returns the pointer.

  - If size does not fall in smallbin range:
    1. Get index into largebin array to access an appropriate bin according to the request size.
    2. See if `av` has fastchunks or not. This is done by checking the `FASTCHUNKS_BIT` in `av->flags`. If so, call `malloc_consolidate` on `av`.

5. If no pointer has yet been returned, this signifies one or more of the following cases:
   1. Size falls into 'fastbin' range but no fastchunk is available.
   2. Size falls into 'smallbin' range but no smallchunk is available(calls `malloc_consolidate` during intialization).
   3. Size falls into 'largbin' range.

6. Next, unsorted chunks are checked and traversed chunks are placed into bins. This is the only place where chunks are placed into bins. Iterate the unsorted bin from the 'TAIL'.
   1. `victim` points to the current chunk being considered.
   2. Check if `victim`'s chunk size is within minimum(`2*SIZE_SZ`) and maximum(`av->system_mem`) range. Throw an error("malloc(): memory corruption") otherwise.
   3. If (size of requested chunk falls in smallbin range) and (`victim` is the last remainder chunk) and (it is the only chunk in the unsorted bin) and (the chunks size >= the one requested):
      1. Break the chunk into 2 chunks:
         - The first chunk matches the size requested and is returned.
         - Left over chunk becomes the new last remainder chunk. It is inserted back into the unsorted bin.
      2. Set `chunk_size` and `chunk_prev_size` fields appropriately for both chunks.
      3. The first chunk is returned after calling `alloc_perturb`.
  4. If the above condition is false, control reaches here. Remove `victim` from the unsorted bin. If size of `victim` matches the size requested exactly, return this chunk after calling `alloc_perturb`.
  5. If `victim`'s size falls in smallbin range:
     1. Add the chunk in the appropriate smallbin.
     Else insert into appropriate largebin while maintaining sorted order:
     1. First checks the last chunk(smallest). If `victim` is smaller than last chunk, insert it at the last.
     2. Otherwise, loop to find a chunk with size >= size of `victim`. If size is exactly same, always insert in the second position.
  6. Repeat this whole step a maximum of `MAX_ITERS`(10000) times or till all chunks in unsorted bin get exhausted.

7. After checking unsorted chunks, check if requested size does not fall in smallbin range, if so then check largebins.
   1. Get index into largebin array to access an appropriate bin according to the request size.
   2. If size of the largest chunk(the first chunk in the bin) is greater than the size requested:
      1. Iterate from 'TAIL' to find a chunk(`victim`) with the smallest size >= the requested size.
      2. Call `unlink` to remove the `victim` chunk from the bin.
      3. Calculate `remainder_size` for the `victim`'s chunk(this will be `victim`'s chunk size - requested size).
      4. If this `remainder_size` >= `MINSIZE`(the minimum chunk size including the headers), split the chunk into two chunks. Otherwise, the entire `victim` chunk will be returned. Insert the remainder chunk in unsorted bin(at the 'TAIL' end). A check is made in unsorted bin whether `unsorted_chunks(av)->fd->bk == unsorted_chunks(av)`. An error is thrown otherwise("malloc(): corrupted unsorted chunks").
      5. Return the `victim` chunk after calling `alloc_perturb`.

8. Till now, we have checked unsorted bin and also the respective fast, small or large bin. Note that a single bin(fast, small or large) was checked according to the size of the requested chunk. Repeat the following steps till all bins are exhausted:
   1. The index into binarray is incremented to check the next bin.
   2. Use `av->binmap` map to skip over bins that are empty.
   3. `victim` is pointed to the 'TAIL' of the current bin.
   4. Using the binmap ensures that if a bin is skipped(in the above 2nd step), it is defintely empty. However, it does not ensure that all empty bins will be skipped. Check if victim is empty or not. If empty, again skip the bin and repeat the above process(or 'continue' this loop) till we arive at a non empty bin.
   5. Split the chunk(`victim` points to the last chunk of a non empty bin) into two chunks. Insert the remainder chunk in unsorted bin(at the 'TAIL' end). A check is made in unsorted bin whether `unsorted_chunks(av)->fd->bk == unsorted_chunks(av)`. An error is thrown otherwise("malloc(): corrupted unsorted chunks 2").
   6. Return the `victim` chunk after calling `alloc_perturb`.

9. If still no empty bin is found, 'top' chunk will be used to service the request:
   1. `victim` points to `av->top`.
   2. If size of 'top' chunk >= 'requested size' + `MINSIZE`, split it into two chunks. In this case, the remainder chunk becomes the new 'top' chunk and the other chunk is returned to the user after calling `alloc_perturb`.
   3. See if `av` has fastchunks or not. This is done by checking the `FASTCHUNKS_BIT` in `av->flags`. If so, call `malloc_consolidate` on `av`. Return to step 6(where we check unsorted bin).
   4. If `av` does not have fastchunks, call `sysmalloc` and return the pointer obtained after calling `alloc_perturb`.

## __libc_malloc (size_t bytes)

1. Calls `arena_get` to get an `mstate` pointer.
2. Calls `_int_malloc` with the arena pointer and the size.
3. Unlockes the arena.
4. Before returning the pointer to the chunk, one of the following should be true:
  - Returned pointer is NULL
  - Chunk is MMAPPED
  - Arena for chunk is the same as the one found in 1.

# API functions

## malloc()

```c
/*
  malloc(size_t n)
  Returns a pointer to a newly allocated chunk of at least n bytes, or null
  if no space is available. Additionally, on failure, errno is
  set to ENOMEM on ANSI C systems.

  If n is zero, malloc returns a minumum-sized chunk. (The minimum
  size is 16 bytes on most 32bit systems, and 24 or 32 bytes on 64bit
  systems.)  On most systems, size_t is an unsigned type, so calls
  with negative arguments are interpreted as requests for huge amounts
  of space, which will often fail. The maximum supported value of n
  differs across systems, but is in all cases less than the maximum
  representable value of a size_t.
*/
```

## free()

```c
/*
  free(void* p)
  Releases the chunk of memory pointed to by p, that had been previously
  allocated using malloc or a related routine such as realloc.
  It has no effect if p is null. It can have arbitrary (i.e., bad!)
  effects if p has already been freed.

  Unless disabled (using mallopt), freeing very large spaces will
  when possible, automatically trigger operations that give
  back unused memory to the system, thus reducing program footprint.
*/
```
